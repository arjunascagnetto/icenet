{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T08:00:20.825970Z",
     "start_time": "2025-04-27T08:00:20.790156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Percorso del file .tfrecord\n",
    "tfrecord_file = \"/home/arjuna_scagnetto/icenet/network_datasets/tutorial_data/north/val/00000011.tfrecord\"\n",
    "\n",
    "# Creare un dataset da un file .tfrecord\n",
    "raw_dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "\n",
    "# Funzione per decodificare un singolo record\n",
    "def parse_example(example_proto):\n",
    "    # Definire le feature attese nel record\n",
    "    feature_description = {\n",
    "        'feature_name': tf.io.FixedLenFeature([], tf.string),  # Modifica in base al tuo caso\n",
    "    }\n",
    "    # Decodificare il record\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "# Applicare la funzione di parsing al dataset\n",
    "parsed_dataset = raw_dataset.map(parse_example)"
   ],
   "id": "dc7a8e7bd09f189e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T07:54:45.226825Z",
     "start_time": "2025-04-27T07:54:45.146155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analizzare il primo record per ottenere la struttura\n",
    "for raw_record in raw_dataset.take(1):  # Prendi solo il primo record\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "\n",
    "    # Estrai la struttura delle feature\n",
    "    features = example.features.feature\n",
    "    for key, feature in features.items():\n",
    "        print(f\"Feature: {key}\")\n",
    "        if feature.HasField(\"bytes_list\"):\n",
    "            print(\"  Tipo: bytes_list\")\n",
    "        elif feature.HasField(\"int64_list\"):\n",
    "            print(\"  Tipo: int64_list\")\n",
    "        elif feature.HasField(\"float_list\"):\n",
    "            print(\"  Tipo: float_list\")"
   ],
   "id": "3c316892d3e26da5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: y\n",
      "  Tipo: float_list\n",
      "Feature: sample_weights\n",
      "  Tipo: float_list\n",
      "Feature: x\n",
      "  Tipo: float_list\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T08:00:54.130055Z",
     "start_time": "2025-04-27T08:00:53.997919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for record in parsed_dataset.take(1):  # Prendi solo il primo record\n",
    "    print(\"Shape di y:\", record['y'].shape)\n",
    "    print(\"Shape di sample_weights:\", record['sample_weights'].shape)\n",
    "    print(\"Shape di x:\", record['x'].shape)"
   ],
   "id": "8d68112ba5c55d95",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 08:00:54.045430: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Feature: feature_name (data type: string) is required but could not be found.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Feature: feature_name (data type: string) is required but could not be found.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mInvalidArgumentError\u001B[39m                      Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m parsed_dataset.take(\u001B[32m1\u001B[39m):  \u001B[38;5;66;03m# Prendi solo il primo record\u001B[39;00m\n\u001B[32m      2\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mShape di y:\u001B[39m\u001B[33m\"\u001B[39m, record[\u001B[33m'\u001B[39m\u001B[33my\u001B[39m\u001B[33m'\u001B[39m].shape)\n\u001B[32m      3\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mShape di sample_weights:\u001B[39m\u001B[33m\"\u001B[39m, record[\u001B[33m'\u001B[39m\u001B[33msample_weights\u001B[39m\u001B[33m'\u001B[39m].shape)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/venv0/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001B[39m, in \u001B[36mOwnedIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    808\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    809\u001B[39m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m810\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._next_internal()\n\u001B[32m    811\u001B[39m   \u001B[38;5;28;01mexcept\u001B[39;00m errors.OutOfRangeError:\n\u001B[32m    812\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/venv0/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001B[39m, in \u001B[36mOwnedIterator._next_internal\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    770\u001B[39m \u001B[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001B[39;00m\n\u001B[32m    771\u001B[39m \u001B[38;5;66;03m# to communicate that there is no more data to iterate over.\u001B[39;00m\n\u001B[32m    772\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context.execution_mode(context.SYNC):\n\u001B[32m--> \u001B[39m\u001B[32m773\u001B[39m   ret = gen_dataset_ops.iterator_get_next(\n\u001B[32m    774\u001B[39m       \u001B[38;5;28mself\u001B[39m._iterator_resource,\n\u001B[32m    775\u001B[39m       output_types=\u001B[38;5;28mself\u001B[39m._flat_output_types,\n\u001B[32m    776\u001B[39m       output_shapes=\u001B[38;5;28mself\u001B[39m._flat_output_shapes)\n\u001B[32m    778\u001B[39m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    779\u001B[39m     \u001B[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001B[39;00m\n\u001B[32m    780\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._element_spec._from_compatible_tensor_list(ret)  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/venv0/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3029\u001B[39m, in \u001B[36miterator_get_next\u001B[39m\u001B[34m(iterator, output_types, output_shapes, name)\u001B[39m\n\u001B[32m   3027\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[32m   3028\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m _core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m3029\u001B[39m   _ops.raise_from_not_ok_status(e, name)\n\u001B[32m   3030\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m _core._FallbackException:\n\u001B[32m   3031\u001B[39m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/venv0/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5883\u001B[39m, in \u001B[36mraise_from_not_ok_status\u001B[39m\u001B[34m(e, name)\u001B[39m\n\u001B[32m   5881\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mraise_from_not_ok_status\u001B[39m(e, name) -> NoReturn:\n\u001B[32m   5882\u001B[39m   e.message += (\u001B[33m\"\u001B[39m\u001B[33m name: \u001B[39m\u001B[33m\"\u001B[39m + \u001B[38;5;28mstr\u001B[39m(name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m-> \u001B[39m\u001B[32m5883\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m core._status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[31mInvalidArgumentError\u001B[39m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Feature: feature_name (data type: string) is required but could not be found.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
