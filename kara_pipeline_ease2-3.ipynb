{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d6f270",
   "metadata": {},
   "source": [
    "# Pipeline EASE2‑3 km – Kara Sea sea‑ice forecast\n",
    "\n",
    "End‑to‑end workflow that downloads / pre‑processes ERA5 + OSI‑SAF data at 3 km, builds PyTorch datasets and trains a UNet‑lite model to predict sea‑ice formation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c5a921",
   "metadata": {},
   "source": [
    "## 1 Overview\n",
    "```\n",
    "┌──────────────┐   ┌────────────┐   ┌─────────────┐   ┌───────────────┐   ┌───────────┐\n",
    "│  Download &  │   │ Re‑grid to │   │ Crop + Mask │   │  DataLoader   │   │  CNN/UNet │\n",
    "│  Averaging   ├──►│  EASE2‑3   ├──►│ 313×313 ROI │──►│  + Normalise  ├──►│  Training │\n",
    "└──────────────┘   └────────────┘   └─────────────┘   └───────────────┘   └────┬──────┘\n",
    "                                                                                │ preds\n",
    "                                                                                ▼\n",
    "                                                                            Post‑proc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf08451",
   "metadata": {},
   "source": [
    "## 2 Source datasets\n",
    "| Source | Variables (daily) | Coverage | Native res. | Tool |\n",
    "|--------|-------------------|----------|-------------|------|\n",
    "| ERA5 (CDS) | uas, vas, tas (single), zg250, zg500 (pressure) | 1979‑present | 0.25° | custom `ERA5Downloader` |\n",
    "| OSI‑SAF SIC v2p0 | sea‑ice concentration | 1979‑present | EASE2‑25 km | re‑gridded to 3 km |\n",
    "| Land/Sea mask | water_mask | NH | EASE2‑3 km | script |\n",
    "| Bathymetry (optional) | GEBCO | global | ~500 m | preprocess |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5434c94",
   "metadata": {},
   "source": [
    "## 3 Patched ERA5Downloader (ease_target & bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ice_patch_era5.py\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np\n",
    "import iris\n",
    "from icenet.data.interfaces.downloader import ClimateDownloader\n",
    "\n",
    "class ERA5Downloader(ClimateDownloader):\n",
    "    \"\"\"ERA5 downloader with `ease_target` (e.g. 'EASE2-3') and `bbox` support.\"\"\"\n",
    "\n",
    "    def __init__(self, *args,\n",
    "                 ease_target: str = \"EASE2-25\",\n",
    "                 bbox: Optional[Tuple[float, float, float, float]] = None,\n",
    "                 **kwargs):\n",
    "        self._ease_target = ease_target\n",
    "        self._bbox = bbox\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    # 1) dynamic template cube\n",
    "    @property\n",
    "    def sic_ease_cube(self):\n",
    "        if self._ease_target not in self._sic_ease_cubes:\n",
    "            if self._ease_target == \"EASE2-25\":\n",
    "                return super().sic_ease_cube\n",
    "            from iris.coord_systems import PolarStereo\n",
    "            from iris.coords import DimCoord\n",
    "            if self.north:\n",
    "                crs = PolarStereo(central_longitude=45, true_scale_latitude=70,\n",
    "                                  latitude_of_projection_origin=90)\n",
    "            else:\n",
    "                crs = PolarStereo(central_longitude=0, true_scale_latitude=-71,\n",
    "                                  latitude_of_projection_origin=-90)\n",
    "            res_km = float(self._ease_target.split(\"-\")[1])\n",
    "            nx = ny = 313  # Kara ROI size, tweak if needed\n",
    "            x = DimCoord(np.arange(nx) * res_km*1000,\n",
    "                         'projection_x_coordinate', units='m', coord_system=crs)\n",
    "            y = DimCoord(np.arange(ny) * res_km*1000,\n",
    "                         'projection_y_coordinate', units='m', coord_system=crs)\n",
    "            template = iris.cube.Cube(np.zeros((ny, nx), np.float32),\n",
    "                                       dim_coords_and_dims=[(y,0),(x,1)])\n",
    "            self._sic_ease_cubes[self._ease_target] = template\n",
    "        return self._sic_ease_cubes[self._ease_target]\n",
    "\n",
    "    # 2) override download request to add bbox\n",
    "    def _single_api_download(self, var, level, req_dates, download_path):\n",
    "        retrieve_dict = self._build_request_dict(var, level, req_dates)\n",
    "        if self._bbox:\n",
    "            lon_w, lat_s, lon_e, lat_n = self._bbox\n",
    "            retrieve_dict['area'] = [lat_n, lon_w, lat_s, lon_e]\n",
    "        else:\n",
    "            retrieve_dict['area'] = self.hemisphere_loc\n",
    "        return super()._single_api_download(var, level, req_dates, download_path)\n",
    "\n",
    "    def _build_request_dict(self, var, level, req_dates):\n",
    "        var_prefix = var[:-len(str(level))] if level else var\n",
    "        return {\n",
    "            \"product_type\":\"reanalysis\",\n",
    "            \"variable\":self._cdi_map[var_prefix],\n",
    "            \"year\":req_dates[0].year,\n",
    "            \"month\": list({f\"{d.month:02d}\" for d in req_dates}),\n",
    "            \"day\":[f\"{d:02d}\" for d in range(1,32)],\n",
    "            \"time\":[f\"{h:02d}:00\" for h in range(24)],\n",
    "            \"format\":\"netcdf\",\n",
    "            **({\"pressure_level\":level} if level else {})\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a19f3",
   "metadata": {},
   "source": [
    "### Re‑grid lat‑lon NetCDF to EASE2‑3 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid_kara.py\n",
    "import iris, numpy as np\n",
    "from icenet.data.utils import assign_lat_lon_coord_system\n",
    "\n",
    "KARA_TEMPLATE = iris.load_cube(\"template_ease2-3_kara.nc\")  # 313×313\n",
    "\n",
    "def regrid_latlon_to_ease3(latlon_nc: str, out_nc: str):\n",
    "    cube = iris.load_cube(latlon_nc)\n",
    "    cube = assign_lat_lon_coord_system(cube)\n",
    "    cube_e3 = cube.regrid(KARA_TEMPLATE, iris.analysis.Linear())\n",
    "    iris.save(cube_e3, out_nc, fill_value=np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18708ab5",
   "metadata": {},
   "source": [
    "### ERA5 post‑processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e86776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postproc_vars.py\n",
    "import iris\n",
    "from icenet.data.utils import gridcell_angles_from_dim_coords, invert_gridcell_angles, rotate_grid_vectors\n",
    "\n",
    "TEMPLATE = iris.load_cube(\"template_ease2-3_kara.nc\")\n",
    "\n",
    "def postprocess_var(nc_path: str):\n",
    "    cube = iris.load_cube(nc_path)\n",
    "    name = cube.name()\n",
    "    if name in (\"zg250\", \"zg500\"):\n",
    "        cube.data /= 9.80665\n",
    "        cube.units = \"m\"\n",
    "        iris.save(cube, nc_path, fill_value=np.nan)\n",
    "    elif name == \"tas\" and cube.units == \"K\":\n",
    "        cube.convert_units(\"celsius\")\n",
    "        iris.save(cube, nc_path, fill_value=np.nan)\n",
    "\n",
    "def rotate_uas_vas(u_nc: str, v_nc: str):\n",
    "    uas = iris.load_cube(u_nc)\n",
    "    vas = iris.load_cube(v_nc)\n",
    "    angles = gridcell_angles_from_dim_coords(TEMPLATE)\n",
    "    invert_gridcell_angles(angles)\n",
    "    uas_r, vas_r = rotate_grid_vectors(uas, vas, angles)\n",
    "    iris.save(uas_r, u_nc, fill_value=np.nan)\n",
    "    iris.save(vas_r, v_nc, fill_value=np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420b395",
   "metadata": {},
   "source": [
    "### OSI‑SAF SIC download + regrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0372a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# osisaf_sic_download_regrid.py\n",
    "import os, subprocess, numpy as np, iris\n",
    "from datetime import date, timedelta\n",
    "\n",
    "FTP_ROOT = \"ftp://osisaf.met.no/reprocessed/ice/conc/v2p0\"\n",
    "HEMI = \"nh\"\n",
    "KARA_TEMPLATE = iris.load_cube(\"template_ease2-3_kara.nc\")\n",
    "\n",
    "def wget_day(ymd: date, dest=\"sic25_raw\"):\n",
    "    fname = f\"ice_conc_{HEMI}_ease2-250_cdr-v2p0_{ymd:%Y%m%d}1200.nc\"\n",
    "    url = f\"{FTP_ROOT}/{ymd.year}/{ymd:%m}/{fname}\"\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "    out = os.path.join(dest, fname)\n",
    "    if not os.path.exists(out):\n",
    "        subprocess.run([\"wget\",\"-q\",\"-nc\",\"-P\",dest,url], check=True)\n",
    "    return out\n",
    "\n",
    "def regrid_sic25_to_3(raw_nc, out_nc):\n",
    "    cube = iris.load_cube(raw_nc, \"sea_ice_area_fraction\")\n",
    "    for c in (\"projection_x_coordinate\",\"projection_y_coordinate\"):\n",
    "        cube.coord(c).convert_units(\"meters\")\n",
    "    cube_e3 = cube.regrid(KARA_TEMPLATE, iris.analysis.Linear())\n",
    "    iris.save(cube_e3.astype(np.float32), out_nc, fill_value=np.nan)\n",
    "\n",
    "def main(start=date(1979,1,1), end=date(2024,12,31)):\n",
    "    raw_dir, out_dir = \"sic25_raw\", \"sic3k\"\n",
    "    cur = start\n",
    "    while cur <= end:\n",
    "        raw = wget_day(cur, raw_dir)\n",
    "        out = os.path.join(out_dir,\n",
    "               os.path.basename(raw).replace(\"ease2-250\",\"ease2-3k\"))\n",
    "        if not os.path.exists(out):\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            regrid_sic25_to_3(raw, out)\n",
    "        cur += timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e6f0f",
   "metadata": {},
   "source": [
    "## 5 Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76af8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_kara.py\n",
    "import xarray as xr, numpy as np, torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IceNetKaraDataset(Dataset):\n",
    "    def __init__(self, zarr_path, lag_days=28, horizon=1, split='train',\n",
    "                 val_years=(2018,), test_years=(2022,)):\n",
    "        ds = xr.open_zarr(zarr_path, consolidated=True)\n",
    "        years = xr.apply_ufunc(lambda t: t.dt.year, ds.time).values\n",
    "        if split == 'train':\n",
    "            idx = ~np.isin(years, val_years + test_years)\n",
    "        elif split == 'val':\n",
    "            idx = np.isin(years, val_years)\n",
    "        else:\n",
    "            idx = np.isin(years, test_years)\n",
    "\n",
    "        self.ds = ds.isel(time=idx).chunk({})\n",
    "        self.lag, self.h = lag_days, horizon\n",
    "        self.mask = xr.open_dataarray(\"watermask_kara_EASE2-3km.nc\").astype(np.float32)\n",
    "        self.pred_vars = [v for v in ds.data_vars if v != 'sea_ice_area_fraction']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds.time) - self.lag - self.h\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        t0 = i + self.lag - 1\n",
    "        win = self.ds.isel(time=slice(i, t0+1))\n",
    "        chans=[]\n",
    "        for v in self.pred_vars:\n",
    "            chans.append(win[v].data)           # (lag,H,W)\n",
    "        x = np.stack(chans,1).reshape(-1,*chans[0].shape[-2:]).astype(np.float32)\n",
    "        sic_now = win['sea_ice_area_fraction'].isel(time=-1).data.astype(np.float32)\n",
    "        x = np.concatenate([x, sic_now[None]],0)\n",
    "        sic_fut = self.ds['sea_ice_area_fraction'].isel(time=t0+self.h).data\n",
    "        y = (sic_fut >= 0.15).astype(np.float32)\n",
    "        m = self.mask.data\n",
    "        return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader_kara.py\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset_kara import IceNetKaraDataset\n",
    "\n",
    "def get_loaders(zarr_path, batch_size=8, lag_days=28, horizon=1):\n",
    "    train_ds = IceNetKaraDataset(zarr_path, lag_days=lag_days, horizon=horizon, split='train')\n",
    "    val_ds   = IceNetKaraDataset(zarr_path, lag_days=lag_days, horizon=horizon, split='val')\n",
    "    train_ld = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_ld   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    return train_ld, val_ld\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
